{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ef5c5-b207-4afa-888f-0bbfcf904c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps\n",
    "\n",
    "# Import large Mt5 model\n",
    "# bring in dataset\n",
    "# Fine tune\n",
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ca90da3-e1ed-4022-8015-0744b984766f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T21:48:52.672775Z",
     "iopub.status.busy": "2023-07-16T21:48:52.671995Z",
     "iopub.status.idle": "2023-07-16T21:48:52.991989Z",
     "shell.execute_reply": "2023-07-16T21:48:52.991420Z",
     "shell.execute_reply.started": "2023-07-16T21:48:52.672760Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad_es (/root/.cache/huggingface/datasets/squad_es/v1.1.0/1.1.0/bcada4f600192451443b95e24f609325705c5185b8aad97bffa8bc3784a867ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3649e257cc040f1bfe7a0b502165a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Bring in dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"squad_es\",'v1.1.0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4de7879-ebb6-41a7-8892-fe1ec7b051da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T20:44:18.228549Z",
     "iopub.status.busy": "2023-07-16T20:44:18.227669Z",
     "iopub.status.idle": "2023-07-16T20:44:18.233107Z",
     "shell.execute_reply": "2023-07-16T20:44:18.232517Z",
     "shell.execute_reply.started": "2023-07-16T20:44:18.228515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87595\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d9c96-64c4-4be2-aed6-c1a5b635d2b5",
   "metadata": {},
   "source": [
    "## Data Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5cfe7edb-df61-45b6-982b-cf9cea459d39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T22:06:14.995650Z",
     "iopub.status.busy": "2023-07-16T22:06:14.994859Z",
     "iopub.status.idle": "2023-07-16T22:06:15.004084Z",
     "shell.execute_reply": "2023-07-16T22:06:15.003538Z",
     "shell.execute_reply.started": "2023-07-16T22:06:14.995624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id value 5733be284776f41900661182\n",
      "id value 5733be284776f4190066117f\n",
      "id value 5733be284776f41900661180\n",
      "id value 5733be284776f41900661181\n",
      "id value 5733be284776f4190066117e\n",
      "id value 5733bf84d058e614000b61be\n",
      "id value 5733bf84d058e614000b61bf\n",
      "id value 5733bf84d058e614000b61c0\n",
      "id value 5733bf84d058e614000b61bd\n",
      "id value 5733bf84d058e614000b61c1\n"
     ]
    }
   ],
   "source": [
    "# Step 1 and 2: Combine context and question, format the answer\n",
    "\n",
    "# Start with a subset of your data for testing\n",
    "train_subset = dataset['train'][:10]  # Adjust this as needed\n",
    "\n",
    "# Create new lists for our inputs and answers\n",
    "inputs = []\n",
    "answers = []\n",
    "\n",
    "# Iterate over each item in the train_subset data\n",
    "for id_value, title_value, context_value in zip(train_subset['id'], train_subset['title'], train_subset['context']):\n",
    "    # Combine the context and question into a single string\n",
    "    input_str = \"context: \" + context_value + \" question: \" + title_value\n",
    "    inputs.append(input_str)\n",
    "    \n",
    "    print(\"id value\",id_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd91eaba-b6f6-4646-b83a-7fbded3c12eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T22:11:53.571243Z",
     "iopub.status.busy": "2023-07-16T22:11:53.570549Z",
     "iopub.status.idle": "2023-07-16T22:11:53.594833Z",
     "shell.execute_reply": "2023-07-16T22:11:53.594132Z",
     "shell.execute_reply.started": "2023-07-16T22:11:53.571211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': ['5733be284776f41900661182',\n",
       "  '5733be284776f4190066117f',\n",
       "  '5733be284776f41900661180',\n",
       "  '5733be284776f41900661181',\n",
       "  '5733be284776f4190066117e',\n",
       "  '5733bf84d058e614000b61be',\n",
       "  '5733bf84d058e614000b61bf',\n",
       "  '5733bf84d058e614000b61c0',\n",
       "  '5733bf84d058e614000b61bd',\n",
       "  '5733bf84d058e614000b61c1'],\n",
       " 'title': ['Universidad _ de _ Notre _ Dame',\n",
       "  'Universidad _ de _ Notre _ Dame',\n",
       "  'Universidad _ de _ Notre _ Dame',\n",
       "  'Universidad _ de _ Notre _ Dame',\n",
       "  'Universidad _ de _ Notre _ Dame',\n",
       "  'Universidad _ de _ Notre _ Dame',\n",
       "  'Universidad _ de _ Notre _ Dame',\n",
       "  'Universidad _ de _ Notre _ Dame',\n",
       "  'Universidad _ de _ Notre _ Dame',\n",
       "  'Universidad _ de _ Notre _ Dame'],\n",
       " 'context': ['Arquitect贸nicamente, la escuela tiene un car谩cter cat贸lico. Encima de la c煤pula de oro del edificio principal hay una estatua dorada de la Virgen Mar铆a. Inmediatamente delante del edificio principal y frente a 茅l, hay una estatua de cobre de Cristo con los brazos levantados con la leyenda \"Venite Ad Me Omnes\". Junto al edificio principal est谩 la Bas铆lica del Sagrado Coraz贸n. Inmediatamente detr谩s de la bas铆lica est谩 la Gruta, un lugar mariano de oraci贸n y reflexi贸n. Es una r茅plica de la gruta de Lourdes, Francia, donde la Virgen Mar铆a supuestamente se le apareci贸 a Santa Bernadette Soubirous en 1858. Al final de la unidad principal (y en una l铆nea directa que se conecta a trav茅s de 3 estatuas y la C煤pula de Oro), hay una simple y moderna estatua de piedra de Mar铆a.',\n",
       "  'Arquitect贸nicamente, la escuela tiene un car谩cter cat贸lico. Encima de la c煤pula de oro del edificio principal hay una estatua dorada de la Virgen Mar铆a. Inmediatamente delante del edificio principal y frente a 茅l, hay una estatua de cobre de Cristo con los brazos levantados con la leyenda \"Venite Ad Me Omnes\". Junto al edificio principal est谩 la Bas铆lica del Sagrado Coraz贸n. Inmediatamente detr谩s de la bas铆lica est谩 la Gruta, un lugar mariano de oraci贸n y reflexi贸n. Es una r茅plica de la gruta de Lourdes, Francia, donde la Virgen Mar铆a supuestamente se le apareci贸 a Santa Bernadette Soubirous en 1858. Al final de la unidad principal (y en una l铆nea directa que se conecta a trav茅s de 3 estatuas y la C煤pula de Oro), hay una simple y moderna estatua de piedra de Mar铆a.',\n",
       "  'Arquitect贸nicamente, la escuela tiene un car谩cter cat贸lico. Encima de la c煤pula de oro del edificio principal hay una estatua dorada de la Virgen Mar铆a. Inmediatamente delante del edificio principal y frente a 茅l, hay una estatua de cobre de Cristo con los brazos levantados con la leyenda \"Venite Ad Me Omnes\". Junto al edificio principal est谩 la Bas铆lica del Sagrado Coraz贸n. Inmediatamente detr谩s de la bas铆lica est谩 la Gruta, un lugar mariano de oraci贸n y reflexi贸n. Es una r茅plica de la gruta de Lourdes, Francia, donde la Virgen Mar铆a supuestamente se le apareci贸 a Santa Bernadette Soubirous en 1858. Al final de la unidad principal (y en una l铆nea directa que se conecta a trav茅s de 3 estatuas y la C煤pula de Oro), hay una simple y moderna estatua de piedra de Mar铆a.',\n",
       "  'Arquitect贸nicamente, la escuela tiene un car谩cter cat贸lico. Encima de la c煤pula de oro del edificio principal hay una estatua dorada de la Virgen Mar铆a. Inmediatamente delante del edificio principal y frente a 茅l, hay una estatua de cobre de Cristo con los brazos levantados con la leyenda \"Venite Ad Me Omnes\". Junto al edificio principal est谩 la Bas铆lica del Sagrado Coraz贸n. Inmediatamente detr谩s de la bas铆lica est谩 la Gruta, un lugar mariano de oraci贸n y reflexi贸n. Es una r茅plica de la gruta de Lourdes, Francia, donde la Virgen Mar铆a supuestamente se le apareci贸 a Santa Bernadette Soubirous en 1858. Al final de la unidad principal (y en una l铆nea directa que se conecta a trav茅s de 3 estatuas y la C煤pula de Oro), hay una simple y moderna estatua de piedra de Mar铆a.',\n",
       "  'Arquitect贸nicamente, la escuela tiene un car谩cter cat贸lico. Encima de la c煤pula de oro del edificio principal hay una estatua dorada de la Virgen Mar铆a. Inmediatamente delante del edificio principal y frente a 茅l, hay una estatua de cobre de Cristo con los brazos levantados con la leyenda \"Venite Ad Me Omnes\". Junto al edificio principal est谩 la Bas铆lica del Sagrado Coraz贸n. Inmediatamente detr谩s de la bas铆lica est谩 la Gruta, un lugar mariano de oraci贸n y reflexi贸n. Es una r茅plica de la gruta de Lourdes, Francia, donde la Virgen Mar铆a supuestamente se le apareci贸 a Santa Bernadette Soubirous en 1858. Al final de la unidad principal (y en una l铆nea directa que se conecta a trav茅s de 3 estatuas y la C煤pula de Oro), hay una simple y moderna estatua de piedra de Mar铆a.',\n",
       "  \"Como en la mayor铆a de las otras universidades, los estudiantes de Notre Dame tienen una serie de medios de comunicaci贸n. Los nueve puntos de venta dirigidos por estudiantes incluyen tres peri贸dicos, tanto una estaci贸n de radio y televisi贸n, y varias revistas y diarios. Comenz贸 como una revista de una p谩gina en septiembre de 1876, la revista Scholastic se publica dos veces al mes y afirma ser la publicaci贸n colegial continua m谩s antigua de los Estados Unidos. La otra revista, The Juggler, se publica dos veces al a帽o y se centra en la literatura estudiantil y el arte. El anuario Dome se publica anualmente. Los peri贸dicos tienen diferentes intereses de publicaci贸n, con The Observer publicado diariamente y principalmente reportando la universidad y otras noticias, y el personal de estudiantes de Notre Dame y Saint Mary 's College. A diferencia de Scholastic y The Dome, The Observer es una publicaci贸n independiente y no tiene un asesor de la facultad ni ninguna supervisi贸n editorial de la Universidad. En 1987, cuando algunos estudiantes cre铆an que The Observer comenz贸 a mostrar un sesgo conservador, un peri贸dico liberal, Common Sense fue publicado. Del mismo modo, en 2003, cuando otros estudiantes cre铆an que el peri贸dico mostraba un sesgo liberal, el peri贸dico conservador Irish Rover entr贸 en producci贸n. Ning煤n peri贸dico es publicado tan a menudo como The Observer; Sin embargo, los tres est谩n distribuidos a todos los estudiantes. Finalmente, en la primavera de 2008, una revista de pregrado para investigaci贸n en ciencias pol铆ticas, Beyond Politics, hizo su debut.\",\n",
       "  \"Como en la mayor铆a de las otras universidades, los estudiantes de Notre Dame tienen una serie de medios de comunicaci贸n. Los nueve puntos de venta dirigidos por estudiantes incluyen tres peri贸dicos, tanto una estaci贸n de radio y televisi贸n, y varias revistas y diarios. Comenz贸 como una revista de una p谩gina en septiembre de 1876, la revista Scholastic se publica dos veces al mes y afirma ser la publicaci贸n colegial continua m谩s antigua de los Estados Unidos. La otra revista, The Juggler, se publica dos veces al a帽o y se centra en la literatura estudiantil y el arte. El anuario Dome se publica anualmente. Los peri贸dicos tienen diferentes intereses de publicaci贸n, con The Observer publicado diariamente y principalmente reportando la universidad y otras noticias, y el personal de estudiantes de Notre Dame y Saint Mary 's College. A diferencia de Scholastic y The Dome, The Observer es una publicaci贸n independiente y no tiene un asesor de la facultad ni ninguna supervisi贸n editorial de la Universidad. En 1987, cuando algunos estudiantes cre铆an que The Observer comenz贸 a mostrar un sesgo conservador, un peri贸dico liberal, Common Sense fue publicado. Del mismo modo, en 2003, cuando otros estudiantes cre铆an que el peri贸dico mostraba un sesgo liberal, el peri贸dico conservador Irish Rover entr贸 en producci贸n. Ning煤n peri贸dico es publicado tan a menudo como The Observer; Sin embargo, los tres est谩n distribuidos a todos los estudiantes. Finalmente, en la primavera de 2008, una revista de pregrado para investigaci贸n en ciencias pol铆ticas, Beyond Politics, hizo su debut.\",\n",
       "  \"Como en la mayor铆a de las otras universidades, los estudiantes de Notre Dame tienen una serie de medios de comunicaci贸n. Los nueve puntos de venta dirigidos por estudiantes incluyen tres peri贸dicos, tanto una estaci贸n de radio y televisi贸n, y varias revistas y diarios. Comenz贸 como una revista de una p谩gina en septiembre de 1876, la revista Scholastic se publica dos veces al mes y afirma ser la publicaci贸n colegial continua m谩s antigua de los Estados Unidos. La otra revista, The Juggler, se publica dos veces al a帽o y se centra en la literatura estudiantil y el arte. El anuario Dome se publica anualmente. Los peri贸dicos tienen diferentes intereses de publicaci贸n, con The Observer publicado diariamente y principalmente reportando la universidad y otras noticias, y el personal de estudiantes de Notre Dame y Saint Mary 's College. A diferencia de Scholastic y The Dome, The Observer es una publicaci贸n independiente y no tiene un asesor de la facultad ni ninguna supervisi贸n editorial de la Universidad. En 1987, cuando algunos estudiantes cre铆an que The Observer comenz贸 a mostrar un sesgo conservador, un peri贸dico liberal, Common Sense fue publicado. Del mismo modo, en 2003, cuando otros estudiantes cre铆an que el peri贸dico mostraba un sesgo liberal, el peri贸dico conservador Irish Rover entr贸 en producci贸n. Ning煤n peri贸dico es publicado tan a menudo como The Observer; Sin embargo, los tres est谩n distribuidos a todos los estudiantes. Finalmente, en la primavera de 2008, una revista de pregrado para investigaci贸n en ciencias pol铆ticas, Beyond Politics, hizo su debut.\",\n",
       "  \"Como en la mayor铆a de las otras universidades, los estudiantes de Notre Dame tienen una serie de medios de comunicaci贸n. Los nueve puntos de venta dirigidos por estudiantes incluyen tres peri贸dicos, tanto una estaci贸n de radio y televisi贸n, y varias revistas y diarios. Comenz贸 como una revista de una p谩gina en septiembre de 1876, la revista Scholastic se publica dos veces al mes y afirma ser la publicaci贸n colegial continua m谩s antigua de los Estados Unidos. La otra revista, The Juggler, se publica dos veces al a帽o y se centra en la literatura estudiantil y el arte. El anuario Dome se publica anualmente. Los peri贸dicos tienen diferentes intereses de publicaci贸n, con The Observer publicado diariamente y principalmente reportando la universidad y otras noticias, y el personal de estudiantes de Notre Dame y Saint Mary 's College. A diferencia de Scholastic y The Dome, The Observer es una publicaci贸n independiente y no tiene un asesor de la facultad ni ninguna supervisi贸n editorial de la Universidad. En 1987, cuando algunos estudiantes cre铆an que The Observer comenz贸 a mostrar un sesgo conservador, un peri贸dico liberal, Common Sense fue publicado. Del mismo modo, en 2003, cuando otros estudiantes cre铆an que el peri贸dico mostraba un sesgo liberal, el peri贸dico conservador Irish Rover entr贸 en producci贸n. Ning煤n peri贸dico es publicado tan a menudo como The Observer; Sin embargo, los tres est谩n distribuidos a todos los estudiantes. Finalmente, en la primavera de 2008, una revista de pregrado para investigaci贸n en ciencias pol铆ticas, Beyond Politics, hizo su debut.\",\n",
       "  \"Como en la mayor铆a de las otras universidades, los estudiantes de Notre Dame tienen una serie de medios de comunicaci贸n. Los nueve puntos de venta dirigidos por estudiantes incluyen tres peri贸dicos, tanto una estaci贸n de radio y televisi贸n, y varias revistas y diarios. Comenz贸 como una revista de una p谩gina en septiembre de 1876, la revista Scholastic se publica dos veces al mes y afirma ser la publicaci贸n colegial continua m谩s antigua de los Estados Unidos. La otra revista, The Juggler, se publica dos veces al a帽o y se centra en la literatura estudiantil y el arte. El anuario Dome se publica anualmente. Los peri贸dicos tienen diferentes intereses de publicaci贸n, con The Observer publicado diariamente y principalmente reportando la universidad y otras noticias, y el personal de estudiantes de Notre Dame y Saint Mary 's College. A diferencia de Scholastic y The Dome, The Observer es una publicaci贸n independiente y no tiene un asesor de la facultad ni ninguna supervisi贸n editorial de la Universidad. En 1987, cuando algunos estudiantes cre铆an que The Observer comenz贸 a mostrar un sesgo conservador, un peri贸dico liberal, Common Sense fue publicado. Del mismo modo, en 2003, cuando otros estudiantes cre铆an que el peri贸dico mostraba un sesgo liberal, el peri贸dico conservador Irish Rover entr贸 en producci贸n. Ning煤n peri贸dico es publicado tan a menudo como The Observer; Sin embargo, los tres est谩n distribuidos a todos los estudiantes. Finalmente, en la primavera de 2008, una revista de pregrado para investigaci贸n en ciencias pol铆ticas, Beyond Politics, hizo su debut.\"],\n",
       " 'question': ['驴A qui茅n acudi贸 la Virgen Mar铆a supuestamente en 1858 en Lourdes France?',\n",
       "  '驴Qu茅 hay frente al edificio principal de Notre Dame?',\n",
       "  'La Bas铆lica del Sagrado Coraz贸n en Notre Dame est谩 al lado de qu茅 estructura?',\n",
       "  '驴Qu茅 es la Gruta de Notre Dame?',\n",
       "  '驴Qu茅 se encuentra en la parte superior del edificio principal de Notre Dame?',\n",
       "  '驴Cu谩ndo comenz贸 la revista escol谩stica de Notre Dame?',\n",
       "  '驴Con qu茅 frecuencia se publica el Juggler de Notre Dame?',\n",
       "  '驴C贸mo se llama el peri贸dico estudiantil diario de Notre Dame?',\n",
       "  '驴Cu谩ntos peri贸dicos de estudiantes se encuentran en Notre Dame?',\n",
       "  '驴En qu茅 a帽o comenz贸 la publicaci贸n del peri贸dico estudiantil Common Sense en Notre Dame?'],\n",
       " 'answers': [{'text': ['Santa Bernadette Soubirous'], 'answer_start': [572]},\n",
       "  {'text': ['una estatua de cobre de Cristo'], 'answer_start': [218]},\n",
       "  {'text': ['el edificio principal'], 'answer_start': [88]},\n",
       "  {'text': ['un lugar mariano de oraci贸n y reflexi贸n'], 'answer_start': [430]},\n",
       "  {'text': ['una estatua dorada de la Virgen Mar铆a'], 'answer_start': [114]},\n",
       "  {'text': ['de una p谩gina en septiembre de 1876'], 'answer_start': [295]},\n",
       "  {'text': ['dos veces'], 'answer_start': [504]},\n",
       "  {'text': ['The Observer'], 'answer_start': [675]},\n",
       "  {'text': ['tres peri贸dicos'], 'answer_start': [182]},\n",
       "  {'text': ['1987'], 'answer_start': [1015]}]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "094a6a02-7272-42cd-bb16-10c5f4c38f88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T22:24:09.226043Z",
     "iopub.status.busy": "2023-07-16T22:24:09.225271Z",
     "iopub.status.idle": "2023-07-16T22:24:10.827517Z",
     "shell.execute_reply": "2023-07-16T22:24:10.826773Z",
     "shell.execute_reply.started": "2023-07-16T22:24:09.226043Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/google/mt5-base/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/4764ec347af4d2d6286acbe1d9d630ac0afd8554a4c4a64170e0b663fd2e2412.84ea7af2df68dc8db434d3160aab65cce8ac63ce5b6f7743f8c9a4a14b4f77e2\n",
      "loading file https://huggingface.co/google/mt5-base/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/mt5-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/mt5-base/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/0d7d5b3fc19bf58d4b274990c8bcf5e307726bc18d95f40a1436dfb6a0892f85.294ebaa4cd17bb284635004c92d2c4d522ec488c828dcce0c2471b6f28e3fe82\n",
      "loading file https://huggingface.co/google/mt5-base/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/afba33be693521ccefbde6d03b93b5c517d7108ba31f6c08000ed52c2cea45c9.28bbf90ae7962b1b7211c0ce8b2006f968c82439ec9c47e0847ba63642f9435a\n",
      "loading configuration file https://huggingface.co/google/mt5-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5ebfd830555547194403d6803baa127970de59b443c04b7a1a60b16a97ed3958.b589da7dac64196f9764abaf2c4c7e507cec8b14b96da3ef270d924f155062de\n",
      "Model config MT5Config {\n",
      "  \"_name_or_path\": \"google/mt5-base\",\n",
      "  \"architectures\": [\n",
      "    \"MT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"mt5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250112\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/mt5-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5ebfd830555547194403d6803baa127970de59b443c04b7a1a60b16a97ed3958.b589da7dac64196f9764abaf2c4c7e507cec8b14b96da3ef270d924f155062de\n",
      "Model config MT5Config {\n",
      "  \"_name_or_path\": \"google/mt5-base\",\n",
      "  \"architectures\": [\n",
      "    \"MT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"mt5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250112\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [259, 220933, 1790, 32294, 261, 283, 259, 60876, 2812, 335, 259, 58878, 41742, 10292, 108405, 260, 642, 22472, 269, 283, 37795, 54126, 269, 16347, 426, 259, 39909, 268, 6017, 2318, 573, 99834, 262, 123281, 262, 269, 283, 89306, 278, 259, 24952, 260, 563, 87060, 259, 63047, 426, 259, 39909, 268, 6017, 259, 276, 259, 20189, 259, 262, 7938, 261, 2318, 573, 99834, 262, 269, 56333, 265, 269, 39333, 450, 595, 259, 98838, 263, 57692, 2131, 450, 283, 340, 116073, 313, 30702, 15782, 4515, 1517, 3548, 1865, 1191, 4143, 476, 440, 259, 39909, 268, 6017, 1957, 283, 364, 7590, 33858, 426, 1560, 15905, 7090, 56019, 260, 563, 87060, 269, 70774, 269, 283, 330, 7590, 33858, 1957, 283, 27166, 422, 261, 335, 5967, 207462, 268, 269, 259, 211457, 259, 276, 130784, 1790, 260, 1659, 573, 1888, 94336, 269, 283, 10937, 422, 269, 458, 133796, 261, 39233, 261, 259, 7497, 283, 89306, 278, 259, 24952, 259, 216207, 1664, 303, 340, 44406, 2711, 259, 262, 5909, 60442, 4549, 16856, 7377, 6836, 289, 259, 116096, 260, 1151, 2733, 269, 283, 259, 85890, 6017, 274, 276, 289, 573, 259, 19921, 3867, 262, 319, 303, 57850, 259, 262, 9587, 1134, 269, 381, 99834, 358, 259, 276, 283, 371, 801, 54126, 269, 23977, 506, 2318, 573, 5431, 259, 276, 4472, 262, 99834, 262, 269, 17893, 571, 269, 259, 24952, 260, 4228, 357, 907, 1979, 15242, 53677, 283, 89306, 278, 259, 24952, 259, 216207, 1664, 289, 259, 116096, 289, 458, 133796, 5263, 291, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Input: [259, 220933, 1790, 32294, 261, 283, 259, 60876, 2812, 335, 259, 58878, 41742, 10292, 108405, 260, 642, 22472, 269, 283, 37795, 54126, 269, 16347, 426, 259, 39909, 268, 6017, 2318, 573, 99834, 262, 123281, 262, 269, 283, 89306, 278, 259, 24952, 260, 563, 87060, 259, 63047, 426, 259, 39909, 268, 6017, 259, 276, 259, 20189, 259, 262, 7938, 261, 2318, 573, 99834, 262, 269, 56333, 265, 269, 39333, 450, 595, 259, 98838, 263, 57692, 2131, 450, 283, 340, 116073, 313, 30702, 15782, 4515, 1517, 3548, 1865, 1191, 4143, 476, 440, 259, 39909, 268, 6017, 1957, 283, 364, 7590, 33858, 426, 1560, 15905, 7090, 56019, 260, 563, 87060, 269, 70774, 269, 283, 330, 7590, 33858, 1957, 283, 27166, 422, 261, 335, 5967, 207462, 268, 269, 259, 211457, 259, 276, 130784, 1790, 260, 1659, 573, 1888, 94336, 269, 283, 10937, 422, 269, 458, 133796, 261, 39233, 261, 259, 7497, 283, 89306, 278, 259, 24952, 259, 216207, 1664, 303, 340, 44406, 2711, 259, 262, 5909, 60442, 4549, 16856, 7377, 6836, 289, 259, 116096, 260, 1151, 2733, 269, 283, 259, 85890, 6017, 274, 276, 289, 573, 259, 19921, 3867, 262, 319, 303, 57850, 259, 262, 9587, 1134, 269, 381, 99834, 358, 259, 276, 283, 371, 801, 54126, 269, 23977, 506, 2318, 573, 5431, 259, 276, 4472, 262, 99834, 262, 269, 17893, 571, 269, 259, 24952, 260, 4228, 16650, 2318, 259, 20189, 440, 259, 39909, 268, 6017, 269, 259, 37126, 34600, 291, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Input: [259, 220933, 1790, 32294, 261, 283, 259, 60876, 2812, 335, 259, 58878, 41742, 10292, 108405, 260, 642, 22472, 269, 283, 37795, 54126, 269, 16347, 426, 259, 39909, 268, 6017, 2318, 573, 99834, 262, 123281, 262, 269, 283, 89306, 278, 259, 24952, 260, 563, 87060, 259, 63047, 426, 259, 39909, 268, 6017, 259, 276, 259, 20189, 259, 262, 7938, 261, 2318, 573, 99834, 262, 269, 56333, 265, 269, 39333, 450, 595, 259, 98838, 263, 57692, 2131, 450, 283, 340, 116073, 313, 30702, 15782, 4515, 1517, 3548, 1865, 1191, 4143, 476, 440, 259, 39909, 268, 6017, 1957, 283, 364, 7590, 33858, 426, 1560, 15905, 7090, 56019, 260, 563, 87060, 269, 70774, 269, 283, 330, 7590, 33858, 1957, 283, 27166, 422, 261, 335, 5967, 207462, 268, 269, 259, 211457, 259, 276, 130784, 1790, 260, 1659, 573, 1888, 94336, 269, 283, 10937, 422, 269, 458, 133796, 261, 39233, 261, 259, 7497, 283, 89306, 278, 259, 24952, 259, 216207, 1664, 303, 340, 44406, 2711, 259, 262, 5909, 60442, 4549, 16856, 7377, 6836, 289, 259, 116096, 260, 1151, 2733, 269, 283, 259, 85890, 6017, 274, 276, 289, 573, 259, 19921, 3867, 262, 319, 303, 57850, 259, 262, 9587, 1134, 269, 381, 99834, 358, 259, 276, 283, 371, 801, 54126, 269, 23977, 506, 2318, 573, 5431, 259, 276, 4472, 262, 99834, 262, 269, 17893, 571, 269, 259, 24952, 260, 501, 364, 7590, 33858, 426, 1560, 15905, 7090, 56019, 289, 259, 37126, 34600, 1957, 440, 17220, 269, 259, 6162, 259, 30886, 291, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Input: [259, 220933, 1790, 32294, 261, 283, 259, 60876, 2812, 335, 259, 58878, 41742, 10292, 108405, 260, 642, 22472, 269, 283, 37795, 54126, 269, 16347, 426, 259, 39909, 268, 6017, 2318, 573, 99834, 262, 123281, 262, 269, 283, 89306, 278, 259, 24952, 260, 563, 87060, 259, 63047, 426, 259, 39909, 268, 6017, 259, 276, 259, 20189, 259, 262, 7938, 261, 2318, 573, 99834, 262, 269, 56333, 265, 269, 39333, 450, 595, 259, 98838, 263, 57692, 2131, 450, 283, 340, 116073, 313, 30702, 15782, 4515, 1517, 3548, 1865, 1191, 4143, 476, 440, 259, 39909, 268, 6017, 1957, 283, 364, 7590, 33858, 426, 1560, 15905, 7090, 56019, 260, 563, 87060, 269, 70774, 269, 283, 330, 7590, 33858, 1957, 283, 27166, 422, 261, 335, 5967, 207462, 268, 269, 259, 211457, 259, 276, 130784, 1790, 260, 1659, 573, 1888, 94336, 269, 283, 10937, 422, 269, 458, 133796, 261, 39233, 261, 259, 7497, 283, 89306, 278, 259, 24952, 259, 216207, 1664, 303, 340, 44406, 2711, 259, 262, 5909, 60442, 4549, 16856, 7377, 6836, 289, 259, 116096, 260, 1151, 2733, 269, 283, 259, 85890, 6017, 274, 276, 289, 573, 259, 19921, 3867, 262, 319, 303, 57850, 259, 262, 9587, 1134, 269, 381, 99834, 358, 259, 276, 283, 371, 801, 54126, 269, 23977, 506, 2318, 573, 5431, 259, 276, 4472, 262, 99834, 262, 269, 17893, 571, 269, 259, 24952, 260, 4228, 16650, 655, 283, 27166, 422, 269, 259, 37126, 34600, 291, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Input: [259, 220933, 1790, 32294, 261, 283, 259, 60876, 2812, 335, 259, 58878, 41742, 10292, 108405, 260, 642, 22472, 269, 283, 37795, 54126, 269, 16347, 426, 259, 39909, 268, 6017, 2318, 573, 99834, 262, 123281, 262, 269, 283, 89306, 278, 259, 24952, 260, 563, 87060, 259, 63047, 426, 259, 39909, 268, 6017, 259, 276, 259, 20189, 259, 262, 7938, 261, 2318, 573, 99834, 262, 269, 56333, 265, 269, 39333, 450, 595, 259, 98838, 263, 57692, 2131, 450, 283, 340, 116073, 313, 30702, 15782, 4515, 1517, 3548, 1865, 1191, 4143, 476, 440, 259, 39909, 268, 6017, 1957, 283, 364, 7590, 33858, 426, 1560, 15905, 7090, 56019, 260, 563, 87060, 269, 70774, 269, 283, 330, 7590, 33858, 1957, 283, 27166, 422, 261, 335, 5967, 207462, 268, 269, 259, 211457, 259, 276, 130784, 1790, 260, 1659, 573, 1888, 94336, 269, 283, 10937, 422, 269, 458, 133796, 261, 39233, 261, 259, 7497, 283, 89306, 278, 259, 24952, 259, 216207, 1664, 303, 340, 44406, 2711, 259, 262, 5909, 60442, 4549, 16856, 7377, 6836, 289, 259, 116096, 260, 1151, 2733, 269, 283, 259, 85890, 6017, 274, 276, 289, 573, 259, 19921, 3867, 262, 319, 303, 57850, 259, 262, 9587, 1134, 269, 381, 99834, 358, 259, 276, 283, 371, 801, 54126, 269, 23977, 506, 2318, 573, 5431, 259, 276, 4472, 262, 99834, 262, 269, 17893, 571, 269, 259, 24952, 260, 4228, 16650, 303, 259, 20347, 262, 289, 283, 1943, 11924, 426, 259, 39909, 268, 6017, 269, 259, 37126, 34600, 291, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1 and 2: Combine context and question, format the answer\n",
    "from transformers import T5TokenizerFast\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = T5TokenizerFast.from_pretrained('google/mt5-base')\n",
    "\n",
    "# Start with a subset of your data for testing\n",
    "train_subset = dataset['train'][:10]  # Adjust this as needed\n",
    "\n",
    "# Create new lists for our inputs and answers\n",
    "input_ids = []\n",
    "answers = []\n",
    "\n",
    "for id_value, title_value, context_value, q_value, a_value in zip(train_subset['id'], train_subset['title'], train_subset['context'],train_subset['question'],train_subset['answers']):\n",
    "    \n",
    "    \n",
    "    # Combine the context and question into a single string\n",
    "    input_str = context_value + \" \" + q_value\n",
    "    #print(input_str)\n",
    "    \n",
    "    #tokenize the inputs\n",
    "    inputs = tokenizer(input_str, truncation=True, padding='max_length', max_length=512)\n",
    "    #print(inputs.input_ids)\n",
    "    input_ids.append(inputs.input_ids)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Format the answer (assuming there's always exactly one answer)\n",
    "    #answer_str = example['answers']['text'][0]\n",
    "    #answers.append(answer_str)\n",
    "    \n",
    "\n",
    "# Check the first few examples to make sure everything looks good\n",
    "for i in range(5):\n",
    "    print(f\"Input: {input_ids[i]}\")\n",
    "    #print(f\"Answer: {answers[i]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc3eef00-b65a-4aa6-a6bb-251cffa03d01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T21:21:13.806771Z",
     "iopub.status.busy": "2023-07-16T21:21:13.806269Z",
     "iopub.status.idle": "2023-07-16T21:21:13.811336Z",
     "shell.execute_reply": "2023-07-16T21:21:13.810857Z",
     "shell.execute_reply.started": "2023-07-16T21:21:13.806748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example in your dataset appears to be correctly structured.\n"
     ]
    }
   ],
   "source": [
    "# Extract one example from each tensor\n",
    "sample = {\n",
    "    'input_ids': train_data['input_ids'][0],\n",
    "    'attention_mask': train_data['attention_mask'][0],\n",
    "    'labels': train_data['labels'][0]\n",
    "}\n",
    "\n",
    "assert isinstance(sample, dict), \"Each item in dataset must be a dictionary\"\n",
    "assert 'input_ids' in sample, \"input_ids must be in the dataset\"\n",
    "assert 'attention_mask' in sample, \"attention_mask must be in the dataset\"\n",
    "assert 'labels' in sample, \"labels must be in the dataset\"\n",
    "\n",
    "print(\"An example in your dataset appears to be correctly structured.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d873825-fed8-4bdc-8244-248fddc4eae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T21:48:35.347602Z",
     "iopub.status.busy": "2023-07-16T21:48:35.346942Z",
     "iopub.status.idle": "2023-07-16T21:48:35.352889Z",
     "shell.execute_reply": "2023-07-16T21:48:35.352174Z",
     "shell.execute_reply.started": "2023-07-16T21:48:35.347577Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert train_data from dict of lists to list of dicts\n",
    "#validation_data = [dict(zip(validation_data, t)) for t in zip(*validation_data.values())]\n",
    "\n",
    "# Now train_data[0] should work, let's print it\n",
    "#print(validation_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a113f167-13d6-46fc-9718-ead5114233b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T21:48:39.600973Z",
     "iopub.status.busy": "2023-07-16T21:48:39.600200Z",
     "iopub.status.idle": "2023-07-16T21:48:39.603908Z",
     "shell.execute_reply": "2023-07-16T21:48:39.603472Z",
     "shell.execute_reply.started": "2023-07-16T21:48:39.600960Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert train_data from dict of lists to list of dicts\n",
    "#train_data = [dict(zip(train_data, t)) for t in zip(*train_data.values())]\n",
    "\n",
    "# Now train_data[0] should work, let's print it\n",
    "#print(train_data[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f65aea7-c5fc-406a-99e3-7c81f75492a8",
   "metadata": {},
   "source": [
    "## Data ready test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "243cc01a-bef7-40c6-bc18-dccfc03fd5e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T21:24:22.670279Z",
     "iopub.status.busy": "2023-07-16T21:24:22.669395Z",
     "iopub.status.idle": "2023-07-16T21:24:22.675698Z",
     "shell.execute_reply": "2023-07-16T21:24:22.674905Z",
     "shell.execute_reply.started": "2023-07-16T21:24:22.670241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your dataset appears to be correctly structured for Trainer.\n"
     ]
    }
   ],
   "source": [
    "# replace 'train_dataset' with your dataset variable\n",
    "sample = validation_data[0]\n",
    "\n",
    "assert isinstance(sample, dict), \"Each item in dataset must be a dictionary\"\n",
    "assert 'input_ids' in sample, \"input_ids must be in the dataset\"\n",
    "assert 'attention_mask' in sample, \"attention_mask must be in the dataset\"\n",
    "assert 'labels' in sample, \"labels must be in the dataset\"\n",
    "\n",
    "print(\"Your dataset appears to be correctly structured for Trainer.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f781b-e08d-4151-b3a1-bda9cd7f04f4",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8231375-e644-444d-94b6-d00528777b99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T21:24:28.238507Z",
     "iopub.status.busy": "2023-07-16T21:24:28.237757Z",
     "iopub.status.idle": "2023-07-16T21:24:45.597907Z",
     "shell.execute_reply": "2023-07-16T21:24:45.597268Z",
     "shell.execute_reply.started": "2023-07-16T21:24:28.238485Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/google/mt5-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5ebfd830555547194403d6803baa127970de59b443c04b7a1a60b16a97ed3958.b589da7dac64196f9764abaf2c4c7e507cec8b14b96da3ef270d924f155062de\n",
      "Model config MT5Config {\n",
      "  \"_name_or_path\": \"/home/patrick/hugging_face/t5/mt5-base\",\n",
      "  \"architectures\": [\n",
      "    \"MT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"mt5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250112\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/mt5-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/3b7e8056d4ed71d8d7ac2dea78627c4be77ed136399c05b563d4116abfcd9418.1afec9001b62cd5a347e7fd4b664e503ca2377606e11b9ddb8ec1d7b79bc3952\n",
      "All model checkpoint weights were used when initializing MT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of MT5ForConditionalGeneration were initialized from the model checkpoint at google/mt5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MT5ForConditionalGeneration for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 64\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>51.877200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12, training_loss=51.85478909810384, metrics={'train_runtime': 11.0849, 'train_samples_per_second': 17.321, 'train_steps_per_second': 1.083, 'total_flos': 230216857288704.0, 'train_loss': 51.85478909810384, 'epoch': 3.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import MT5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "\n",
    "# Initialize the model\n",
    "model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-base\")\n",
    "\n",
    "# Initialize the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Define the compute metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated  Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_data,            # training dataset\n",
    "    eval_dataset=validation_data,         # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf41775-d5c2-4418-9028-30143767db7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
